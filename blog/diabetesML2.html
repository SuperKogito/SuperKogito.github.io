
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/><meta content="applied machine learning to diabetics detection" name="description"/>
<meta content="machine learning, Pima, classification, diabetes detection, data scaling, knn, svc, gaussian, Ayoub Malek" name="keywords"/>
<meta content="Ayoub Malek" name="author"/>
<script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-133660046-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
<title>Diabetes detection using machine learning (part II) — Ayoub Malek's blog</title>
<link href="../_static/alabaster.css" rel="stylesheet" type="text/css"/>
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom_style.css" rel="stylesheet" type="text/css"/>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script src="../_static/language_data.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<link href="../_static/favicon.ico" rel="shortcut icon"/>
<link href="../about.html" rel="author" title="About these documents"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../_static/custom.css" rel="stylesheet" type="text/css"/>
<meta content="width=device-width, initial-scale=0.9, maximum-scale=0.9" name="viewport"/>
<style type="text/css">
    ul.ablog-archive {list-style: none; overflow: auto; margin-left: 0px}
    ul.ablog-archive li {float: left; margin-right: 5px; font-size: 80%}
    ul.postlist a {font-style: italic;}
    ul.postlist-style-disc {list-style-type: disc;}
    ul.postlist-style-none {list-style-type: none;}
    ul.postlist-style-circle {list-style-type: circle;}
  </style>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/></head><body>
<div class="document">
<div class="documentwrapper">
<div class="body" role="main">
<div class="section" id="diabetes-detection-using-machine-learning-part-ii">
<h1>Diabetes detection using machine learning (part II)<a class="headerlink" href="#diabetes-detection-using-machine-learning-part-ii" title="Permalink to this headline">¶</a></h1>
<div class="sub-title-menu">
<table class="menu-table" id="menuTable" style="border:hidden;">
<tr>
<th>
<th>
<th class="icon"> <a href="../index.html" title="Home"><i class="fa fa-home"></i></a> </th>
<th class="menu-label"> <a href="../index.html" title="Home">Home</a> </th>
</th>
</th>
<th>
<th>
<th class="icon"><a href="../posts.html" title="Posts"><i class="fa fa-bars"></i></a></th>
<th class="menu-label"><a href="../posts.html" title="Posts">Posts</a></th>
</th>
</th>
<th>
<th>
<th class="icon"> <a href="../publications.html" title="pubs"><i class="fa fa-file-text"></i></a></th>
<th class="menu-label"> <a href="../publications.html" title="pubs">Publications</a></th>
</th>
</th>
<th>
<th>
<th class="icon"> <a href="../projects.html" title="projects"><i class="fa fa-code"></i></a></th>
<th class="menu-label"> <a href="../projects.html" title="projects">Projects</a></th>
</th>
</th>
<th>
<th>
<th class="icon"> <a href="../games.html" title="Games"><i class="fa fa-gamepad"></i></a></th>
<th class="menu-label"> <a href="../games.html" title="Games">Games</a></th>
</th>
</th>
<th>
<th>
<th class="icon"><a href="../about.html" title="About"><i class="fa fa-user-circle"></i></a></th>
<th class="menu-label"><a href="../about.html" title="About">About</a></th>
</th>
</th>
<th>
<th>
<th class="icon"> <a href="#" onclick="modeSwitcher()"><i class="fa fa-adjust"></i></a></th>
<th class="menu-label"> <a href="#" onclick="modeSwitcher()"><text id="theme-toggle">DARK MODE</text></a></th>
</th>
</th>
</tr>
</table>
</div>

<div class="blog-post-tags">
<ul class="blog-posts-details">
<li id="Date"><span>Date:</span>                 30 June 2019 </li>
<li id="author"><span>Author:</span> <a href="author/ayoub-malek.html">Ayoub Malek</a> </li>
<li id="location"><span>Location:</span> <a href="location/munich.html">Munich</a>
</li> <li id="language"><span>Language:</span> <a href="language/english.html">English</a>
</li> <li id="category"><span>Category:</span> <a href="category/machine-learning.html"> Machine learning</a>
</li>
<li id="tags"><span>Tags:
        </span>
<a class="post-tags" href="tag/data-processing.html">Data processing</a>
<a class="post-tags" href="tag/visualization.html">Visualization</a>
<a class="post-tags" href="tag/python.html">Python</a>
</li>
</ul>
</div><hr class="docutils"/>
<p>In this 2nd post on detecting diabetes with the help of machine learning and using the Pima Indian diabetic database (<a class="reference external" href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names">PIDD</a>), we will dig into testing various classifiers and evaluating their performances.
We will also examine the performance improvements by the data transformations explained in the previous post.</p>
<div class="section" id="the-tested-machine-learning-detection-approaches">
<h2>The tested machine learning detection approaches<a class="headerlink" href="#the-tested-machine-learning-detection-approaches" title="Permalink to this headline">¶</a></h2>
<p>The idea of the detection in this context is distinguishing based on the provided features if the person has diabetes or not. This is a clear classification problem.
For which we test the following classifiers:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">K-Nearest_Neighbors</a> (KNN)</p>
<ul>
<li><p>K-Nearest Neighbors (distance weights)</p></li>
<li><p>K-Nearest Neighbors (uniform weights)</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Support-vector_machine">Support_Vector_Classifier</a> (SVC)</p>
<ul>
<li><p>Linear Support Vector Classifier</p></li>
<li><p>RBF Support Vector Classifier</p></li>
</ul>
</li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian_Process</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Decision_tree_learning">Decision_Tree</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Random_forest">Random_Forest</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/AdaBoost">AdaBoost</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive_Bayes</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Quadratic_classifier#Quadratic_discriminant_analysis">Quadratic_Discriminant_Analysis</a> (QDA)</p></li>
</ul>
</div>
<div class="section" id="code-and-implementation">
<h2>Code and implementation<a class="headerlink" href="#code-and-implementation" title="Permalink to this headline">¶</a></h2>
<p>
The code for this section is to be found in this script_.
However, the whole project is available in the following  <a href="https://github.com/SuperKogito/Diabetes-detection-using-machine-learning" title="vbgr"><i class="fa fa-github"></i> Diabetes detection</a>.
</p>
<table align="center" style="width:100%">
<tr>
<th> <a aria-label="Watch SuperKogito/Diabetes-detection-using-machine-learning on GitHub" class="github-button" data-show-count="true" data-size="large" href="https://github.com/SuperKogito/Diabetes-detection-using-machine-learning/subscription">Watch</a> </th>
<th> <a aria-label="Star SuperKogito/Diabetes-detection-using-machine-learning on GitHub" class="github-button" data-show-count="true" data-size="large" href="https://github.com/SuperKogito/Diabetes-detection-using-machine-learning">Star</a></th>
<th> <a aria-label="Fork SuperKogito/Diabetes-detection-using-machine-learning on GitHub" class="github-button" data-show-count="true" data-size="large" href="https://github.com/SuperKogito/Diabetes-detection-using-machine-learning/fork">Fork</a> </th>
<th> <a aria-label="Download SuperKogito/Diabetes-detection-using-machine-learning on GitHub" class="github-button" data-size="large" href="https://github.com/SuperKogito/Diabetes-detection-using-machine-learning/archive/master.zip">Download</a></th>
<th> <a aria-label="Follow @SuperKogito on GitHub" class="github-button" data-show-count="true" data-size="large" href="https://github.com/SuperKogito">Follow @SuperKogito</a> </th>
</tr>
</table>
<script async="" defer="" src="https://buttons.github.io/buttons.js"></script><p>The dataset can be Downloaded from <a class="reference external" href="https://github.com/SuperKogito/Diabetes-detection-using-machine-learning/blob/master/diabetes.csv">here</a>.</p>
</div>
<div class="section" id="evaluation-techniques">
<h2>Evaluation techniques<a class="headerlink" href="#evaluation-techniques" title="Permalink to this headline">¶</a></h2>
<p>When facing a typical machine learning classification problem, accuracy values can be deceiving and inaccurate.
Therefore, other metrics such as the confusion matrix, <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Sensitivity</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">Specificity</a> are used to provide a better assessment of the algorithms.</p>
<div class="math notranslate nohighlight" id="equation-specificity-and-sensitivity">
\begin{eqnarray}
    Sensitivity &amp;= \frac{True~Positives}{True~Positives + False~Negatives}\\  \\
    Specificity &amp;= \frac{True~Negatives}{True~Negatives + False~Positives}
\end{eqnarray}</div><p>Consequently, in order to compare the performance of the data transformations and the observed improvements, a plot of their respective accuracy, sensitivity and specificity values is provided.
As for the differences between machine learning approaches, a bars plot is provided to highlight the accuracy, sensitivity and specificity values of each approach.
On top of all, we use the <a class="reference external" href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion_matrix</a> to visualize the performance of an approach and its efficiency.
In this matrix the rows represent the expected outcome and the columns correspond to the predicted ones as shown in the following:</p>
<table class="docutils align-default">
<tr>
<th> </th>
<th> <h4>Predicted outcome is 0 </h4></th>
<th> <h4>Predicted outcome is 1 </h4></th>
</tr>
<tr>
<td> <h4> Actual outcome is 0 </h4> </td>
<td> <h4><font color="green"> True Negatives               </font></h4> </td>
<td> <h4><font color="red">   False Negatives (misses)     </font></h4> </td>
</tr>
<tr>
<td> <h4> Actual outcome is 1 </h4> </td>
<td> <h4><font color="red">   False Positives (false alarms) </font></h4> </td>
<td> <h4><font color="green"> True Positives                 </font></h4> </td>
</tr>
</table><div class="clt">
<br/>
<center><a href="../tables/table3.html">Table 3: Confusion matrix </a> </center>
</div><p>Sensitivity and Specificity are two complementary metrics. Therefore, to judge which of these two metrics to prioritize is dependent on the nature of the problem.
In order to have a better differentiation between these two, let us consider two classification systems:</p>
<br><ol class="arabic simple">
<li><p>First an airport system that based on a passenger behavior and emotions, decides whether the person is suspicious or not and according to the system output the authorities stop the passenger for a chat or not.
So suspicious is outcome 0 (Negative) and not suspicious is outcome 1 (Positive): Now we can have a system that is perfect at detecting the none suspicious passengers but that is worthless in this scenario.
If you let all the possible criminals through, you can simply not even have a system. So in this case, we prioritize the detection of True Negatives and as a side effect we will have some False Negatives (misses).
This means, you achieve the goal of stopping and questioning every criminal but every now and then you will stop some peaceful passengers for some questions.</p></li>
</ol>
<br/><ol class="arabic simple" start="2">
<li><p>Now imagine some pre-selection system for some candidates. The idea here is to select candidates who full-fill certain requirements (features).
Assume 0 for candidates that do not full-fill (Negative) the requirements and 1 for those who do (Positive). In this case, we need to do the opposite of the previous one.
The system is supposed to detect candidates that are good at the expense of some candidates, that might not full-fill all the requirements, getting though.
Therefore, we need to maximize True Positives count and accept the presence of some False Positive (False alarms).</p></li>
</ol>
<div class="section" id="data-transformations-influence-on-results">
<h3>Data transformations influence on results<a class="headerlink" href="#data-transformations-influence-on-results" title="Permalink to this headline">¶</a></h3>
<p>In the previous post, the utility of some data transformations has been discussed as a method to improve the data quality and consequently improve the classification.
the following plots, confirm this as we can clearly see that employing these data transformations (scaling, equalization and outliers removal) results overall in better accuracy, sensitivity and specificity.</p>
<a class="reference internal image-reference" href="../_images/dataTrafos.png"><img alt="../_images/dataTrafos.png" class="align-center" src="../_images/dataTrafos.png" style="width: 1080.0px; height: 576.0px;"/></a>
<div class="clt">
<center><a href="../figures/fig13.html">Figure 13: Influence of data transformations  </a> </center>
</div></div>
<div class="section" id="classifiers-comparison">
<h3>Classifiers comparison<a class="headerlink" href="#classifiers-comparison" title="Permalink to this headline">¶</a></h3>
<p>In this section, we examine the performances of the aforementioned machine learning approaches approaches to diabetes detection.
The plots and the results summary prove that the Support Vector Classifiers clearly results in the best prediction rates.
In this case, we prioritize True Positives detection (sensitivity over simplicity) as we want to detect all of those having diabetes even if it means getting some False Positives (healthy patients diagnosed as diabetics) as that can be dismissed with some extra tests.</p>
<a class="reference internal image-reference" href="../_images/scaled_and_equalized_data_without_outliers-BAR.png"><img alt="../_images/scaled_and_equalized_data_without_outliers-BAR.png" class="align-center" src="../_images/scaled_and_equalized_data_without_outliers-BAR.png" style="width: 1080.0px; height: 540.0px;"/></a>
<div class="clt">
<center><a href="../figures/fig14.html">Figure 14: Performance comparison for different classifiers </a> </center>
</div><div class="line-block">
<div class="line"><br/></div>
</div>
<a class="reference internal image-reference" href="../_images/scaled_and_equalized_data_without_outliers-CM.png"><img alt="../_images/scaled_and_equalized_data_without_outliers-CM.png" class="align-center" src="../_images/scaled_and_equalized_data_without_outliers-CM.png" style="width: 810.0px; height: 270.0px;"/></a>
<div class="clt">
<center><a href="../figures/fig15.html">Figure 15: Confusion matrices for different classifiers </a> </center>
</div><div class="line-block">
<div class="line"><br/></div>
</div>
<div class="literal-block-wrapper docutils container" id="results">
<div class="code-block-caption"><span class="caption-text">Results summary</span><a class="headerlink" href="#results" title="Permalink to this code">¶</a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="o">---------------------------------------------------------------------------------------------------</span>
                                    <span class="n">Classifiers</span> <span class="n">performances</span>
 <span class="o">---------------------------------------------------------------------------------------------------</span>
  <span class="n">KNN</span> <span class="p">(</span><span class="n">distance</span> <span class="n">weights</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.80</span>
  <span class="n">KNN</span> <span class="p">(</span><span class="n">uniform</span> <span class="n">weights</span><span class="p">)</span>  <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.80</span>
  <span class="n">Linear</span> <span class="n">SVC</span>             <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.82</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.86</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.78</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.82</span>
  <span class="n">RBF</span> <span class="n">SVC</span>                <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.82</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.84</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.79</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.82</span>
  <span class="n">Gaussian</span> <span class="n">Process</span>       <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.84</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.77</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.80</span>
  <span class="n">Decision</span> <span class="n">Tree</span>          <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.57</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.59</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.54</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.56</span>
  <span class="n">Random</span> <span class="n">Forest</span>          <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.68</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.77</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.63</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.69</span>
  <span class="n">AdaBoost</span>               <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.75</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.71</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.75</span>
  <span class="n">Naive</span> <span class="n">Bayes</span>            <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.79</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.83</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.75</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.79</span>
  <span class="n">QDA</span>                    <span class="o">-&gt;</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">0.80</span> <span class="o">|</span> <span class="n">Sensitivity</span><span class="p">:</span> <span class="mf">0.86</span> <span class="o">|</span> <span class="n">Specificity</span><span class="p">:</span> <span class="mf">0.76</span> <span class="o">|</span> <span class="n">Average</span><span class="p">:</span> <span class="mf">0.81</span>
 <span class="o">---------------------------------------------------------------------------------------------------</span>
</pre></div>
</div>
</div>
</div>
</br></div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>In these two blog posts, we investigated the utility of various machine learning approaches to diabetes detection and their efficiency.
Moreover, various data transformations, such as scaling, equalization and outliers removal, have been proven to enhance the diabetes detection process.</p>
</div>
<div class="section" id="references-and-further-readings">
<h2>References and Further readings<a class="headerlink" href="#references-and-further-readings" title="Permalink to this headline">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p>Pima Indians Diabetes Database, <a class="reference external" href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names">https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names</a></p>
</dd>
<dt class="label" id="id2"><span class="brackets">2</span></dt>
<dd><p>Igor Shvartser, Jason Brownlee, Case Study: Predicting the Onset of Diabetes Within Five Years (part 1 of 3), March 2014 , <a class="reference external" href="https://machinelearningmastery.com/case-study-predicting-the-onset-of-diabetes-within-five-years-part-1-of-3/">https://machinelearningmastery.com/case-study-predicting-the-onset-of-diabetes-within-five-years-part-1-of-3/</a></p>
</dd>
<dt class="label" id="id3"><span class="brackets">3</span></dt>
<dd><p>Kaggle, Pima Indians Diabetes Database: Predict the onset of diabetes based on diagnostic measures, <a class="reference external" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a></p>
</dd>
<dt class="label" id="id4"><span class="brackets">4</span></dt>
<dd><p>Kaggle kernals, Pima Indians Diabetes Database: Predict the onset of diabetes based on diagnostic measures, <a class="reference external" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database/kernels">https://www.kaggle.com/uciml/pima-indians-diabetes-database/kernels</a></p>
</dd>
</dl>
</div>
</div>
<div class="section">
<div class="section">
<span style="float: left;">
  
  Previous: 
  <a href="diabetesML1.html">
    
    Diabetes detection using machine learning (part I)
  </a>
</span>
<span> </span>
<span style="float: right;">
  
  Next: 
  <a href="SignalFraming.html">
    Signal framing
    
  </a>
</span>
</div>
</div>
</div>
</div>
<div class="clearer"></div>
</div>
<div class="footer">
      ©2020, Ayoub Malek.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.11</a>
      
      |
      <a href="../_sources/blog/diabetesML2.rst.txt" rel="nofollow">Page source</a>
</div><script async="" defer="" src="https://buttons.github.io/buttons.js"></script><script src="../_static/js/mode-switcher.js"></script>
</body>
</html>